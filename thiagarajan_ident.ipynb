{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificación de Retinopatía Diabética con Arquitectura de Aswin Shriram Thiagarajan et al"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: Aswin Shriram Thiagarajan et al., / Journal of Computer Science 2020, 16 (3): 305.313 \n",
    "\n",
    "__DOI: 10.3844/jcssp.2020.305.313__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 14:59:18.663699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "\n",
    "from tesis_lib.nn.thiagarajan import Thiagarajan\n",
    "from tesis_lib.io.hdf5datasetwriter import HDF5DatasetWriter\n",
    "from tesis_lib.io.hdf5datasetgenerator import HDF5DatasetGenerator\n",
    "from tesis_lib.datasets.rosenbrock_loader import RosenbrockLoader\n",
    "from tesis_lib.callbacks.trainingmonitor import TrainingMonitor\n",
    "from tesis_lib.preprocessing.imagetoarrayprocessor import ImageToArrayPreprocessor\n",
    "from tesis_lib.preprocessing.aspectawareprocessor import AspectAwareProcessor\n",
    "from tesis_lib.preprocessing.patchpreprocessor import PatchPreprocessor\n",
    "from tesis_lib.preprocessing.meanpreprocessor import MeanPreprocessor\n",
    "from tesis_lib.preprocessing.simplepreprocessor import SimpleProcessor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "DATASET_PATH = './DB'\n",
    "\n",
    "MODEL_OUT_PATH = f'./models/thiagarajan_{datetime.today().strftime(\"%d_%m_%Y_%H_%M_%S\")}.h5'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "IM_SIZE = 224\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_HDF5_PATH = os.path.sep.join([DATASET_PATH, 'hdf5'])\n",
    "if os.path.exists(DATASET_HDF5_PATH):\n",
    "    !rm -r {DATASET_HDF5_PATH}\n",
    "\n",
    "os.mkdir(DATASET_HDF5_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap = AspectAwareProcessor(IM_SIZE,IM_SIZE)\n",
    "# iap = ImageToArrayPreprocessor()\n",
    "(R,G,B) = ([],[],[])\n",
    "\n",
    "path = os.path.sep.join([DATASET_PATH, \"Training\"])\n",
    "class_paths = [os.path.sep.join([path, im_class]) for im_class in os.listdir(path)]\n",
    "\n",
    "imagePaths = []\n",
    "[imagePaths.extend(paths.list_images(cp)) for cp in class_paths]\n",
    "labels = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "(trainPaths, valPaths,trainLabels,valLabels) = train_test_split(\n",
    "  imagePaths,\n",
    "  labels,\n",
    "  train_size=450,\n",
    "  test_size=100,\n",
    "  stratify=labels, \n",
    "  random_state = 42)\n",
    "\n",
    "assert trainLabels.shape[0] == len(trainPaths)\n",
    "assert valLabels.shape[0] == len(valPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.sep.join([DATASET_PATH, \"Test\"])\n",
    "class_paths = [os.path.sep.join([path, im_class]) for im_class in os.listdir(path)]\n",
    "\n",
    "imagePaths = []\n",
    "[imagePaths.extend(paths.list_images(cp)) for cp in class_paths]\n",
    "labels = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "(_, testPaths,_,testLabels) = train_test_split(\n",
    "  imagePaths,\n",
    "  labels,\n",
    "  train_size=450,\n",
    "  test_size=100,\n",
    "  stratify=labels, \n",
    "  random_state = 42)\n",
    "\n",
    "assert testLabels.shape[0] == len(testPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nOoUuQ4E_2_N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building train Set: 100% |######################################| Time: 0:00:31\n",
      "Building val Set: 100% |########################################| Time: 0:00:09\n",
      "Building test Set: 100% |#######################################| Time: 0:00:11\n"
     ]
    }
   ],
   "source": [
    "DATA_PATHS = [\n",
    "    ('train', trainPaths, trainLabels, f'./DB/hdf5/Training.hdf5'),\n",
    "    ('val', valPaths, valLabels, f'./DB/hdf5/Validation.hdf5'),\n",
    "    ('test', testPaths, testLabels, f'./DB/hdf5/Testing.hdf5'),\n",
    "]\n",
    "\n",
    "for (dType, imagePaths, labels, output) in DATA_PATHS:\n",
    "  if os.path.exists(output):\n",
    "    os.remove(output)\n",
    "  writer = HDF5DatasetWriter((len(imagePaths), IM_SIZE,IM_SIZE,3), output)\n",
    "\n",
    "  widgets = [\n",
    "      f\"Building {dType} Set: \",\n",
    "      progressbar.Percentage(),\n",
    "      \" \",\n",
    "      progressbar.Bar(),\n",
    "      \" \",\n",
    "      progressbar.ETA()\n",
    "  ]\n",
    "\n",
    "  pbar = progressbar.ProgressBar(\n",
    "      maxval=len(imagePaths),\n",
    "      widgets=widgets\n",
    "      ).start()\n",
    "\n",
    "  for (i, (path,label)) in enumerate(zip(imagePaths, labels)):\n",
    "      image = cv2.imread(path)\n",
    "      try:\n",
    "        image = aap.preprocess(image)\n",
    "      except Exception:\n",
    "        display(f\"[WARNING] Skipped {path.split('/')[-1]}\")\n",
    "        continue\n",
    "\n",
    "      if dType == \"train\":\n",
    "        (b,g,r) = cv2.mean(image)[:3]\n",
    "        R.append(r)\n",
    "        G.append(g)\n",
    "        B.append(b)\n",
    "      \n",
    "      writer.add([image], [label])\n",
    "      pbar.update(i)\n",
    "\n",
    "  pbar.finish()\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing means...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] serializing means...\")\n",
    "D = {\n",
    "    \"R\": np.mean(R),\n",
    "    \"G\": np.mean(G),\n",
    "    \"B\": np.mean(B)\n",
    "}\n",
    "with open('./DB/hdf5/diat_ret.json', \"w\") as f:\n",
    "    f.write(json.dumps(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, \n",
    "    shear_range=0.20, \n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = json.loads(open('./DB/hdf5/diat_ret.json').read())\n",
    "\n",
    "sp = SimpleProcessor(IM_SIZE, IM_SIZE)\n",
    "pp = PatchPreprocessor(IM_SIZE,IM_SIZE)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen = HDF5DatasetGenerator(\n",
    "    'DB/hdf5/Training.hdf5',\n",
    "    batchSize=BATCH_SIZE,\n",
    "    aug=aug,\n",
    "    preprocessors=[pp, mp, iap],\n",
    "    classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "valGen = HDF5DatasetGenerator(\n",
    "    'DB/hdf5/Validation.hdf5',\n",
    "    batchSize=BATCH_SIZE,\n",
    "    aug=aug,\n",
    "    preprocessors=[sp, mp, iap],\n",
    "    classes=NUM_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling model ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 74, 74, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 74, 74, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 36, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              42468352  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 42,716,738\n",
      "Trainable params: 42,713,986\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 14:11:49.305238: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-25 14:11:49.305919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-25 14:11:49.317037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3050 Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.5GHz coreCount: 16 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2023-01-25 14:11:49.317084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-25 14:11:49.318587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-25 14:11:49.318710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-25 14:11:49.319922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-25 14:11:49.320151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-25 14:11:49.321078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-25 14:11:49.321872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-25 14:11:49.324470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-25 14:11:49.324867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-25 14:11:49.325187: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 14:11:49.325556: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-25 14:11:49.325840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3050 Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.5GHz coreCount: 16 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2023-01-25 14:11:49.325892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-25 14:11:49.325907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-25 14:11:49.325915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-25 14:11:49.325923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-25 14:11:49.325931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-25 14:11:49.325939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-25 14:11:49.325947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-25 14:11:49.325956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-25 14:11:49.326162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-25 14:11:49.326205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-25 14:15:47.584410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-25 14:15:47.584429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-01-25 14:15:47.584433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-01-25 14:15:47.584903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3078 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Compiling model ...\")\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "\n",
    "model = Thiagarajan.build(\n",
    "    width= IM_SIZE,\n",
    "    height= IM_SIZE,\n",
    "    depth= 3,\n",
    "    classes= NUM_CLASSES\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "monitor_path = os.path.sep.join([\n",
    "    './output/',\n",
    "    f\"{os.getpid()}.jpg\"\n",
    "])\n",
    "\n",
    "callbacks = [TrainingMonitor(monitor_path)]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newton/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 14:15:48.247813: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-25 14:15:48.248073: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3110400000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 14:15:48.792621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-25 14:17:05.374504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 381s 534ms/step - loss: 0.6790 - accuracy: 0.8021 - val_loss: 0.6287 - val_accuracy: 0.8125\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 527ms/step - loss: 0.6064 - accuracy: 0.8280 - val_loss: 0.5629 - val_accuracy: 0.8125\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 486ms/step - loss: 0.5499 - accuracy: 0.8123 - val_loss: 0.5105 - val_accuracy: 0.8125\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 506ms/step - loss: 0.4900 - accuracy: 0.8296 - val_loss: 0.4854 - val_accuracy: 0.8125\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 518ms/step - loss: 0.4619 - accuracy: 0.8307 - val_loss: 0.4837 - val_accuracy: 0.8125\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 0.4873 - accuracy: 0.8114 - val_loss: 0.4881 - val_accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 488ms/step - loss: 0.5531 - accuracy: 0.7748 - val_loss: 0.4884 - val_accuracy: 0.8125\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 476ms/step - loss: 0.5417 - accuracy: 0.7824 - val_loss: 0.4860 - val_accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 532ms/step - loss: 0.5035 - accuracy: 0.8021 - val_loss: 0.4840 - val_accuracy: 0.8125\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 563ms/step - loss: 0.4599 - accuracy: 0.8280 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 482ms/step - loss: 0.4827 - accuracy: 0.8123 - val_loss: 0.4830 - val_accuracy: 0.8125\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 494ms/step - loss: 0.4567 - accuracy: 0.8296 - val_loss: 0.4831 - val_accuracy: 0.8125\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 503ms/step - loss: 0.4569 - accuracy: 0.8307 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.4860 - accuracy: 0.8114 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.5445 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 477ms/step - loss: 0.5323 - accuracy: 0.7824 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 560ms/step - loss: 0.5016 - accuracy: 0.8021 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 580ms/step - loss: 0.4618 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 519ms/step - loss: 0.4836 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 520ms/step - loss: 0.4564 - accuracy: 0.8296 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 540ms/step - loss: 0.4563 - accuracy: 0.8307 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 488ms/step - loss: 0.4846 - accuracy: 0.8114 - val_loss: 0.4837 - val_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 498ms/step - loss: 0.5433 - accuracy: 0.7748 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 484ms/step - loss: 0.5349 - accuracy: 0.7824 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 527ms/step - loss: 0.5004 - accuracy: 0.8021 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 566ms/step - loss: 0.4589 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 498ms/step - loss: 0.4846 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 499ms/step - loss: 0.4571 - accuracy: 0.8296 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 502ms/step - loss: 0.4555 - accuracy: 0.8307 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 499ms/step - loss: 0.4854 - accuracy: 0.8114 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 502ms/step - loss: 0.5421 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 475ms/step - loss: 0.5309 - accuracy: 0.7824 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 521ms/step - loss: 0.4999 - accuracy: 0.8021 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 561ms/step - loss: 0.4612 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 510ms/step - loss: 0.4834 - accuracy: 0.8123 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 510ms/step - loss: 0.4598 - accuracy: 0.8296 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 3s 509ms/step - loss: 0.4546 - accuracy: 0.8307 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 3s 501ms/step - loss: 0.4853 - accuracy: 0.8114 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 3s 510ms/step - loss: 0.5415 - accuracy: 0.7748 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.5308 - accuracy: 0.7824 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 3s 543ms/step - loss: 0.5003 - accuracy: 0.8021 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 3s 561ms/step - loss: 0.4596 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 3s 500ms/step - loss: 0.4841 - accuracy: 0.8123 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.4565 - accuracy: 0.8296 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 3s 499ms/step - loss: 0.4539 - accuracy: 0.8307 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 3s 496ms/step - loss: 0.4850 - accuracy: 0.8114 - val_loss: 0.4837 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 3s 496ms/step - loss: 0.5429 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 3s 487ms/step - loss: 0.5317 - accuracy: 0.7824 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 3s 549ms/step - loss: 0.4970 - accuracy: 0.8021 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 3s 559ms/step - loss: 0.4587 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 3s 502ms/step - loss: 0.4846 - accuracy: 0.8123 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.4557 - accuracy: 0.8296 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 3s 499ms/step - loss: 0.4548 - accuracy: 0.8307 - val_loss: 0.4837 - val_accuracy: 0.8125\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 3s 498ms/step - loss: 0.4842 - accuracy: 0.8114 - val_loss: 0.4837 - val_accuracy: 0.8125\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 3s 498ms/step - loss: 0.5434 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 3s 499ms/step - loss: 0.5302 - accuracy: 0.7824 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 3s 527ms/step - loss: 0.5009 - accuracy: 0.8021 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 3s 565ms/step - loss: 0.4595 - accuracy: 0.8280 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 3s 489ms/step - loss: 0.4828 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 3s 501ms/step - loss: 0.4580 - accuracy: 0.8296 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 3s 502ms/step - loss: 0.4550 - accuracy: 0.8307 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 3s 501ms/step - loss: 0.4867 - accuracy: 0.8114 - val_loss: 0.4837 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 3s 493ms/step - loss: 0.5450 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 3s 464ms/step - loss: 0.5307 - accuracy: 0.7824 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 3s 533ms/step - loss: 0.4993 - accuracy: 0.8021 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 3s 576ms/step - loss: 0.4590 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 3s 506ms/step - loss: 0.4844 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 3s 490ms/step - loss: 0.4574 - accuracy: 0.8296 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.4555 - accuracy: 0.8307 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 3s 509ms/step - loss: 0.4866 - accuracy: 0.8114 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 3s 469ms/step - loss: 0.5468 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 3s 493ms/step - loss: 0.5307 - accuracy: 0.7824 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 3s 536ms/step - loss: 0.4996 - accuracy: 0.8021 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 3s 577ms/step - loss: 0.4592 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 3s 478ms/step - loss: 0.4830 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 3s 496ms/step - loss: 0.4562 - accuracy: 0.8296 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 3s 512ms/step - loss: 0.4548 - accuracy: 0.8307 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 3s 491ms/step - loss: 0.4863 - accuracy: 0.8114 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 3s 494ms/step - loss: 0.5439 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 3s 479ms/step - loss: 0.5332 - accuracy: 0.7824 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 3s 537ms/step - loss: 0.4990 - accuracy: 0.8021 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 3s 573ms/step - loss: 0.4613 - accuracy: 0.8280 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 3s 528ms/step - loss: 0.4854 - accuracy: 0.8123 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 3s 482ms/step - loss: 0.4574 - accuracy: 0.8296 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 3s 501ms/step - loss: 0.4548 - accuracy: 0.8307 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 3s 538ms/step - loss: 0.4837 - accuracy: 0.8114 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 3s 540ms/step - loss: 0.5421 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 3s 527ms/step - loss: 0.5306 - accuracy: 0.7824 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 0.5014 - accuracy: 0.8021 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 3s 572ms/step - loss: 0.4612 - accuracy: 0.8280 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 3s 534ms/step - loss: 0.4835 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 3s 500ms/step - loss: 0.4582 - accuracy: 0.8296 - val_loss: 0.4834 - val_accuracy: 0.8125\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 3s 490ms/step - loss: 0.4565 - accuracy: 0.8307 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.4883 - accuracy: 0.8114 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 3s 490ms/step - loss: 0.5441 - accuracy: 0.7748 - val_loss: 0.4835 - val_accuracy: 0.8125\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 3s 490ms/step - loss: 0.5333 - accuracy: 0.7824 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.5016 - accuracy: 0.8021 - val_loss: 0.4831 - val_accuracy: 0.8125\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 3s 563ms/step - loss: 0.4623 - accuracy: 0.8280 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 3s 492ms/step - loss: 0.4819 - accuracy: 0.8123 - val_loss: 0.4833 - val_accuracy: 0.8125\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 3s 501ms/step - loss: 0.4571 - accuracy: 0.8296 - val_loss: 0.4835 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68404623a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"[INFO] training model ...\")\n",
    "\n",
    "model.fit_generator(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages // BATCH_SIZE,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages // BATCH_SIZE,\n",
    "    epochs= EPOCHS,\n",
    "    max_queue_size=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing model ...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] serializing model ...\")\n",
    "model.save(MODEL_OUT_PATH, overwrite=True)\n",
    "\n",
    "trainGen.close()\n",
    "valGen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/thiagarajan_25_01_2023_14_10_55.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen = HDF5DatasetGenerator(\n",
    "    'DB/hdf5/Testing.hdf5',\n",
    "    batchSize=BATCH_SIZE,\n",
    "    preprocessors=[sp, mp, iap],\n",
    "    classes=NUM_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newton/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
      "2023-01-25 15:25:49.605231: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-01-25 15:25:49.684196: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-01-25 15:25:49.684238: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/activation/Relu (defined at tmp/ipykernel_15572/3304702617.py:1) ]] [Op:__inference_predict_function_2252]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_generator(\n\u001b[1;32m      2\u001b[0m     testGen\u001b[39m.\u001b[39;49mgenerator(),\n\u001b[1;32m      3\u001b[0m     steps\u001b[39m=\u001b[39;49mtestGen\u001b[39m.\u001b[39;49mnumImages \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m64\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1908\u001b[0m, in \u001b[0;36mModel.predict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1899\u001b[0m \u001b[39m\"\"\"Generates predictions for the input samples from a data generator.\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m \n\u001b[1;32m   1901\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m \u001b[39m  `Model.predict` now supports generators, so there is no longer any need\u001b[39;00m\n\u001b[1;32m   1903\u001b[0m \u001b[39m  to use this endpoint.\u001b[39;00m\n\u001b[1;32m   1904\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1905\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.predict_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1906\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1907\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.predict`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1908\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1909\u001b[0m     generator,\n\u001b[1;32m   1910\u001b[0m     steps\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   1911\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1912\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1913\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1914\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1915\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1629\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1628\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1629\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   1630\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1631\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:862\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    860\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    863\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    864\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tesisenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/activation/Relu (defined at tmp/ipykernel_15572/3304702617.py:1) ]] [Op:__inference_predict_function_2252]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(\n",
    "    testGen.generator(),\n",
    "    steps=testGen.numImages // 64, \n",
    "    max_queue_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b78e886a6fb0f84752242253b8c2d087611fa25dd961b88029c1e056ec76052e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
