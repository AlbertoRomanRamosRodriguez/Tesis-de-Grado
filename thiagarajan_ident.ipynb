{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificación de Retinopatía Diabética con Arquitectura de Aswin Shriram Thiagarajan et al"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: Aswin Shriram Thiagarajan et al., / Journal of Computer Science 2020, 16 (3): 305.313 \n",
    "\n",
    "__DOI: 10.3844/jcssp.2020.305.313__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tesis_lib.nn.thiagarajan import Thiagarajan\n",
    "from tesis_lib.io.hdf5datasetgenerator import HDF5DatasetGenerator\n",
    "from tesis_lib.datasets.rosenbrock_loader import RosenbrockLoader\n",
    "from tesis_lib.callbacks.trainingmonitor import TrainingMonitor\n",
    "from tesis_lib.preprocessing.imagetoarrayprocessor import ImageToArrayPreprocessor\n",
    "from tesis_lib.preprocessing.aspectawareprocessor import AspectAwareProcessor\n",
    "from tesis_lib.preprocessing.patchpreprocessor import PatchPreprocessor\n",
    "from tesis_lib.preprocessing.meanpreprocessor import MeanPreprocessor\n",
    "from tesis_lib.preprocessing.simplepreprocessor import SimpleProcessor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STAMP = datetime.today().strftime(\"%d_%m_%Y_%H_%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './DB'\n",
    "\n",
    "FILENAME = f'ident_thiagarajan_{TIME_STAMP}'\n",
    "\n",
    "MODEL_OUT_PATH = f'./models/{FILENAME}.h5'\n",
    "OUTPUT_PATH = F'./output/{FILENAME}'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 75\n",
    "IM_SIZE = 256\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "DROP_FACTOR = 0.10\n",
    "DROP_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = {\n",
    "    'learning-rate' : str(LEARNING_RATE),\n",
    "    'epochs': EPOCHS,\n",
    "    'image-size': IM_SIZE,\n",
    "    'batch-size': BATCH_SIZE,\n",
    "    'data': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, \n",
    "    shear_range=0.20, \n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest')\n",
    "\n",
    "report_dict['augmentation'] = {\n",
    "    'rotation_range': str(aug.rotation_range),\n",
    "    'shear_range': str(aug.shear_range),\n",
    "    'zoom_range': str(aug.zoom_range),\n",
    "    'width_shift_range': str(aug.width_shift_range),\n",
    "    'height_shift_range': str(aug.height_shift_range),\n",
    "    'horizontal_flip': str(aug.horizontal_flip),\n",
    "    'fill_mode': str(aug.fill_mode),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = json.loads(open('./DB/hdf5/diat_ret.json').read())\n",
    "\n",
    "sp = SimpleProcessor(IM_SIZE, IM_SIZE)\n",
    "pp = PatchPreprocessor(IM_SIZE,IM_SIZE)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen = HDF5DatasetGenerator(\n",
    "    'DB/hdf5/Training.hdf5',\n",
    "    batchSize=BATCH_SIZE,\n",
    "    aug=aug,\n",
    "    preprocessors=[pp, mp, iap],\n",
    "    classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "report_dict['data']['trainGen'] = {\n",
    "    'preprocessors': [\n",
    "        'PatchPreprocessor',\n",
    "        'MeanPreprocessor',\n",
    "        'ImageToArrayPreprocessor'\n",
    "    ]\n",
    "}\n",
    "\n",
    "valGen = HDF5DatasetGenerator(\n",
    "    'DB/hdf5/Validation.hdf5',\n",
    "    batchSize=BATCH_SIZE,\n",
    "    aug=aug,\n",
    "    preprocessors=[sp, mp, iap],\n",
    "    classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "report_dict['data']['valGen'] = {\n",
    "    'preprocessors': [\n",
    "        'SimpleProcessor',\n",
    "        'MeanPreprocessor',\n",
    "        'ImageToArrayPreprocessor'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initAlpha = LEARNING_RATE\n",
    "    factor = DROP_FACTOR\n",
    "    dropEvery = DROP_EPOCHS\n",
    "\n",
    "    alpha = initAlpha * (factor ** np.floor((1+epoch) / dropEvery))\n",
    "\n",
    "    return float(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.mkdir(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling model ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 85, 85, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 85, 85, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 85, 85, 64)        18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 85, 85, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 85, 85, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 42, 42, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 42, 42, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 42, 42, 128)       73856     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 42, 42, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 42, 42, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 42, 42, 128)       147584    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 42, 42, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 42, 42, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 21, 21, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 21, 21, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 56448)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              57803776  \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,052,162\n",
      "Trainable params: 58,049,410\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model ...\n",
      "Epoch 1/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.6448 - accuracy: 0.6161\n",
      "Epoch 1: val_loss improved from inf to 6.11082, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 18s 1s/step - loss: 1.6448 - accuracy: 0.6161 - val_loss: 6.1108 - val_accuracy: 0.2292\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.5230 - accuracy: 0.6555\n",
      "Epoch 2: val_loss improved from 6.11082 to 3.73057, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.5230 - accuracy: 0.6555 - val_loss: 3.7306 - val_accuracy: 0.3646\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4490 - accuracy: 0.6914\n",
      "Epoch 3: val_loss did not improve from 3.73057\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.4490 - accuracy: 0.6914 - val_loss: 3.7755 - val_accuracy: 0.3542\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4129 - accuracy: 0.7464\n",
      "Epoch 4: val_loss improved from 3.73057 to 1.46170, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.4129 - accuracy: 0.7464 - val_loss: 1.4617 - val_accuracy: 0.7604\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3663 - accuracy: 0.7823\n",
      "Epoch 5: val_loss improved from 1.46170 to 1.34762, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.3663 - accuracy: 0.7823 - val_loss: 1.3476 - val_accuracy: 0.8125\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2967 - accuracy: 0.8158\n",
      "Epoch 6: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2967 - accuracy: 0.8158 - val_loss: 1.3498 - val_accuracy: 0.8125\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3544 - accuracy: 0.7919\n",
      "Epoch 7: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3544 - accuracy: 0.7919 - val_loss: 1.7638 - val_accuracy: 0.8125\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3389 - accuracy: 0.8134\n",
      "Epoch 8: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3389 - accuracy: 0.8134 - val_loss: 1.8598 - val_accuracy: 0.8021\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3299 - accuracy: 0.8014\n",
      "Epoch 9: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3299 - accuracy: 0.8014 - val_loss: 1.6244 - val_accuracy: 0.8125\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3323 - accuracy: 0.8158\n",
      "Epoch 10: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3323 - accuracy: 0.8158 - val_loss: 1.6481 - val_accuracy: 0.8125\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2935 - accuracy: 0.8158\n",
      "Epoch 11: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2935 - accuracy: 0.8158 - val_loss: 1.4145 - val_accuracy: 0.8438\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2666 - accuracy: 0.8206\n",
      "Epoch 12: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2666 - accuracy: 0.8206 - val_loss: 1.6915 - val_accuracy: 0.7396\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3649 - accuracy: 0.7990\n",
      "Epoch 13: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3649 - accuracy: 0.7990 - val_loss: 2.0265 - val_accuracy: 0.8021\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3089 - accuracy: 0.8158\n",
      "Epoch 14: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3089 - accuracy: 0.8158 - val_loss: 1.8312 - val_accuracy: 0.7708\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3381 - accuracy: 0.7871\n",
      "Epoch 15: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.3381 - accuracy: 0.7871 - val_loss: 1.6418 - val_accuracy: 0.6979\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2717 - accuracy: 0.8393\n",
      "Epoch 16: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.2717 - accuracy: 0.8393 - val_loss: 1.5107 - val_accuracy: 0.7604\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2803 - accuracy: 0.8230\n",
      "Epoch 17: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2803 - accuracy: 0.8230 - val_loss: 2.0202 - val_accuracy: 0.7604\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2873 - accuracy: 0.8230\n",
      "Epoch 18: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2873 - accuracy: 0.8230 - val_loss: 1.5927 - val_accuracy: 0.7812\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2563 - accuracy: 0.8134\n",
      "Epoch 19: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2563 - accuracy: 0.8134 - val_loss: 1.6920 - val_accuracy: 0.8125\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2134 - accuracy: 0.8301\n",
      "Epoch 20: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2134 - accuracy: 0.8301 - val_loss: 1.6846 - val_accuracy: 0.8229\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2144 - accuracy: 0.8182\n",
      "Epoch 21: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.2144 - accuracy: 0.8182 - val_loss: 1.5863 - val_accuracy: 0.6875\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1963 - accuracy: 0.8254\n",
      "Epoch 22: val_loss did not improve from 1.34762\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.1963 - accuracy: 0.8254 - val_loss: 1.5821 - val_accuracy: 0.8333\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1404 - accuracy: 0.8517\n",
      "Epoch 23: val_loss improved from 1.34762 to 1.28824, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.1404 - accuracy: 0.8517 - val_loss: 1.2882 - val_accuracy: 0.8542\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1436 - accuracy: 0.8206\n",
      "Epoch 24: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.1436 - accuracy: 0.8206 - val_loss: 1.4607 - val_accuracy: 0.8229\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.8469\n",
      "Epoch 25: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0983 - accuracy: 0.8469 - val_loss: 1.4936 - val_accuracy: 0.7812\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0554 - accuracy: 0.8517\n",
      "Epoch 26: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0554 - accuracy: 0.8517 - val_loss: 1.5034 - val_accuracy: 0.8021\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0982 - accuracy: 0.8493\n",
      "Epoch 27: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0982 - accuracy: 0.8493 - val_loss: 1.7769 - val_accuracy: 0.7917\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0428 - accuracy: 0.8541\n",
      "Epoch 28: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0428 - accuracy: 0.8541 - val_loss: 1.5393 - val_accuracy: 0.8021\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0596 - accuracy: 0.8206\n",
      "Epoch 29: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0596 - accuracy: 0.8206 - val_loss: 1.3656 - val_accuracy: 0.8021\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0259 - accuracy: 0.8517\n",
      "Epoch 30: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0259 - accuracy: 0.8517 - val_loss: 1.4488 - val_accuracy: 0.7917\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0411 - accuracy: 0.8259\n",
      "Epoch 31: val_loss did not improve from 1.28824\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.0411 - accuracy: 0.8259 - val_loss: 1.4410 - val_accuracy: 0.8125\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0221 - accuracy: 0.8397\n",
      "Epoch 32: val_loss improved from 1.28824 to 1.22364, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.0221 - accuracy: 0.8397 - val_loss: 1.2236 - val_accuracy: 0.7917\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9896 - accuracy: 0.8589\n",
      "Epoch 33: val_loss did not improve from 1.22364\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9896 - accuracy: 0.8589 - val_loss: 1.2612 - val_accuracy: 0.7396\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9730 - accuracy: 0.8469\n",
      "Epoch 34: val_loss improved from 1.22364 to 1.20943, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.9730 - accuracy: 0.8469 - val_loss: 1.2094 - val_accuracy: 0.8125\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9299 - accuracy: 0.8469\n",
      "Epoch 35: val_loss did not improve from 1.20943\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9299 - accuracy: 0.8469 - val_loss: 1.2659 - val_accuracy: 0.8021\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9037 - accuracy: 0.8612\n",
      "Epoch 36: val_loss improved from 1.20943 to 1.14683, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.9037 - accuracy: 0.8612 - val_loss: 1.1468 - val_accuracy: 0.8229\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9377 - accuracy: 0.8541\n",
      "Epoch 37: val_loss did not improve from 1.14683\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9377 - accuracy: 0.8541 - val_loss: 1.3258 - val_accuracy: 0.8021\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9886 - accuracy: 0.8254\n",
      "Epoch 38: val_loss improved from 1.14683 to 1.07325, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.9886 - accuracy: 0.8254 - val_loss: 1.0733 - val_accuracy: 0.8021\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9075 - accuracy: 0.8636\n",
      "Epoch 39: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9075 - accuracy: 0.8636 - val_loss: 1.1756 - val_accuracy: 0.7812\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9318 - accuracy: 0.8469\n",
      "Epoch 40: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9318 - accuracy: 0.8469 - val_loss: 1.1695 - val_accuracy: 0.7604\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.8541\n",
      "Epoch 41: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9317 - accuracy: 0.8541 - val_loss: 1.4021 - val_accuracy: 0.8021\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0594 - accuracy: 0.7943\n",
      "Epoch 42: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0594 - accuracy: 0.7943 - val_loss: 1.0778 - val_accuracy: 0.7604\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9837 - accuracy: 0.8397\n",
      "Epoch 43: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9837 - accuracy: 0.8397 - val_loss: 1.1360 - val_accuracy: 0.8229\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9793 - accuracy: 0.8636\n",
      "Epoch 44: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9793 - accuracy: 0.8636 - val_loss: 1.2169 - val_accuracy: 0.7917\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9499 - accuracy: 0.8517\n",
      "Epoch 45: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9499 - accuracy: 0.8517 - val_loss: 1.1080 - val_accuracy: 0.8229\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9829 - accuracy: 0.8192\n",
      "Epoch 46: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.9829 - accuracy: 0.8192 - val_loss: 1.2987 - val_accuracy: 0.8021\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0742 - accuracy: 0.8134\n",
      "Epoch 47: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0742 - accuracy: 0.8134 - val_loss: 1.3204 - val_accuracy: 0.8021\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1393 - accuracy: 0.8086\n",
      "Epoch 48: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.1393 - accuracy: 0.8086 - val_loss: 1.2073 - val_accuracy: 0.8021\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0924 - accuracy: 0.8469\n",
      "Epoch 49: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0924 - accuracy: 0.8469 - val_loss: 1.2121 - val_accuracy: 0.7500\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0247 - accuracy: 0.8278\n",
      "Epoch 50: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0247 - accuracy: 0.8278 - val_loss: 1.2160 - val_accuracy: 0.7604\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0172 - accuracy: 0.8373\n",
      "Epoch 51: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0172 - accuracy: 0.8373 - val_loss: 1.2434 - val_accuracy: 0.7292\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0442 - accuracy: 0.8325\n",
      "Epoch 52: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0442 - accuracy: 0.8325 - val_loss: 1.2295 - val_accuracy: 0.7500\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0266 - accuracy: 0.8373\n",
      "Epoch 53: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0266 - accuracy: 0.8373 - val_loss: 1.2036 - val_accuracy: 0.7604\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0326 - accuracy: 0.8278\n",
      "Epoch 54: val_loss did not improve from 1.07325\n",
      "14/14 [==============================] - 15s 1s/step - loss: 1.0326 - accuracy: 0.8278 - val_loss: 1.1804 - val_accuracy: 0.7812\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9512 - accuracy: 0.8469\n",
      "Epoch 55: val_loss improved from 1.07325 to 1.06672, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.9512 - accuracy: 0.8469 - val_loss: 1.0667 - val_accuracy: 0.8229\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9312 - accuracy: 0.8421\n",
      "Epoch 56: val_loss did not improve from 1.06672\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9312 - accuracy: 0.8421 - val_loss: 1.1750 - val_accuracy: 0.8021\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9035 - accuracy: 0.8445\n",
      "Epoch 57: val_loss did not improve from 1.06672\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.9035 - accuracy: 0.8445 - val_loss: 1.1581 - val_accuracy: 0.7917\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8704 - accuracy: 0.8565\n",
      "Epoch 58: val_loss did not improve from 1.06672\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8704 - accuracy: 0.8565 - val_loss: 1.1344 - val_accuracy: 0.8125\n",
      "Epoch 59/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.8517\n",
      "Epoch 59: val_loss improved from 1.06672 to 1.05597, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.8846 - accuracy: 0.8517 - val_loss: 1.0560 - val_accuracy: 0.8229\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8473 - accuracy: 0.8589\n",
      "Epoch 60: val_loss improved from 1.05597 to 1.03027, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.8473 - accuracy: 0.8589 - val_loss: 1.0303 - val_accuracy: 0.8021\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.8415\n",
      "Epoch 61: val_loss improved from 1.03027 to 1.00645, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.8628 - accuracy: 0.8415 - val_loss: 1.0065 - val_accuracy: 0.7917\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8304 - accuracy: 0.8684\n",
      "Epoch 62: val_loss did not improve from 1.00645\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8304 - accuracy: 0.8684 - val_loss: 1.0376 - val_accuracy: 0.7812\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8402 - accuracy: 0.8469\n",
      "Epoch 63: val_loss did not improve from 1.00645\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8402 - accuracy: 0.8469 - val_loss: 1.0211 - val_accuracy: 0.8021\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8389 - accuracy: 0.8780\n",
      "Epoch 64: val_loss improved from 1.00645 to 0.97693, saving model to ./models/ident_thiagarajan_30_01_2023_14_30.h5\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.8389 - accuracy: 0.8780 - val_loss: 0.9769 - val_accuracy: 0.7917\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8325 - accuracy: 0.8565\n",
      "Epoch 65: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8325 - accuracy: 0.8565 - val_loss: 1.0710 - val_accuracy: 0.7708\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8596 - accuracy: 0.8517\n",
      "Epoch 66: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8596 - accuracy: 0.8517 - val_loss: 1.0376 - val_accuracy: 0.7917\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8059 - accuracy: 0.8636\n",
      "Epoch 67: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8059 - accuracy: 0.8636 - val_loss: 1.1344 - val_accuracy: 0.8021\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8191 - accuracy: 0.8541\n",
      "Epoch 68: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.8191 - accuracy: 0.8541 - val_loss: 1.0384 - val_accuracy: 0.8021\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.8732\n",
      "Epoch 69: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7879 - accuracy: 0.8732 - val_loss: 1.0613 - val_accuracy: 0.8021\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.8660\n",
      "Epoch 70: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7622 - accuracy: 0.8660 - val_loss: 1.0385 - val_accuracy: 0.7812\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7962 - accuracy: 0.8732\n",
      "Epoch 71: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7962 - accuracy: 0.8732 - val_loss: 1.0253 - val_accuracy: 0.7708\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7544 - accuracy: 0.8660\n",
      "Epoch 72: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7544 - accuracy: 0.8660 - val_loss: 1.1333 - val_accuracy: 0.7812\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.8947\n",
      "Epoch 73: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7350 - accuracy: 0.8947 - val_loss: 1.0526 - val_accuracy: 0.8021\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7778 - accuracy: 0.8589\n",
      "Epoch 74: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7778 - accuracy: 0.8589 - val_loss: 1.0059 - val_accuracy: 0.8021\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7406 - accuracy: 0.8756\n",
      "Epoch 75: val_loss did not improve from 0.97693\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.7406 - accuracy: 0.8756 - val_loss: 1.0386 - val_accuracy: 0.8021\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Compiling model ...\")\n",
    "\n",
    "\n",
    "opt = Adam(lr=LEARNING_RATE)\n",
    "\n",
    "model = Thiagarajan.build(\n",
    "    width= IM_SIZE,\n",
    "    height= IM_SIZE,\n",
    "    depth= 3,\n",
    "    classes= NUM_CLASSES\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "monitor_path = os.path.sep.join([\n",
    "    OUTPUT_PATH,\n",
    "    f\"{FILENAME}.jpg\"\n",
    "])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_OUT_PATH, \n",
    "    monitor=\"val_loss\", \n",
    "    mode='min', \n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint,\n",
    "    # LearningRateScheduler(step_decay),\n",
    "    TrainingMonitor(monitor_path)\n",
    "]\n",
    "\n",
    "display(model.summary())\n",
    "\n",
    "print(f\"[INFO] training model ...\")\n",
    "\n",
    "H = model.fit(\n",
    "    trainGen.generator(),\n",
    "    steps_per_epoch=trainGen.numImages // BATCH_SIZE,\n",
    "    validation_data=valGen.generator(),\n",
    "    validation_steps=valGen.numImages // BATCH_SIZE,\n",
    "    epochs= EPOCHS,\n",
    "    max_queue_size=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict['optimizer'] = {k:str(v) for k,v in opt.get_config().items()}\n",
    "report_dict['checkpoint'] = {\n",
    "    'monitor': checkpoint.monitor,\n",
    "    'best-loss': str(checkpoint.best)\n",
    "}\n",
    "\n",
    "trainGen.close()\n",
    "valGen.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict['data']['testGen'] = {\n",
    "    'preprocessors': [\n",
    "\t\t'SimpleProcessor',\n",
    "\t\t'MeanPreprocessor',\n",
    "\t\t'ImageToArrayPreprocessor'\n",
    "\t]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    MATRIX_PATH = os.path.sep.join([OUTPUT_PATH, f'cm-{FILENAME}.jpg'])\n",
    "    plt.savefig(MATRIX_PATH)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] predicting on test data (no crops)...\n",
      "3/3 [==============================] - 1s 236ms/step\n",
      "[INFO] rank-1: 83.33%\n",
      "\n",
      "\n",
      "[INFO] Calculating Confusion Matrix\n",
      "Confusion matrix, without normalization\n",
      "[[76  2]\n",
      " [14  4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       No DR       0.84      0.97      0.90        78\n",
      "          DR       0.67      0.22      0.33        18\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.76      0.60      0.62        96\n",
      "weighted avg       0.81      0.83      0.80        96\n",
      "\n",
      "[INFO] Calculating the class likelihood ratios\n",
      "|\tClass 0: 8.67\n",
      "|\tClass 1: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, class_likelihood_ratios\n",
    "\n",
    "# from tesis_lib.io.hdf5datasetgenerator import HDF5DatasetGenerator\n",
    "# from tesis_lib.preprocessing.simplepreprocessor import SimpleProcessor\n",
    "# from tesis_lib.preprocessing.meanpreprocessor import MeanPreprocessor\n",
    "# from tesis_lib.preprocessing.croppreprocessor import CropPreprocessor\n",
    "# from tesis_lib.preprocessing.imagetoarrayprocessor import ImageToArrayPreprocessor\n",
    "\n",
    "from tesis_lib.utils.ranked import rank5_accuracy\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import progressbar\n",
    "# import json\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IM_SIZE = 256\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "means = json.loads(open('./DB/hdf5/diat_ret.json').read())\n",
    "\n",
    "sp = SimpleProcessor(IM_SIZE, IM_SIZE)\n",
    "mp = MeanPreprocessor(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the pretrained network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model('models/ident_thiagarajan_30_01_2023_13_40.h5')\n",
    "\n",
    "# initialize the testing dataset generator, then make predictions on\n",
    "# the testing data\n",
    "print(\"[INFO] predicting on test data (no crops)...\")\n",
    "\n",
    "testGen = HDF5DatasetGenerator(\n",
    "\t'./DB/hdf5/Testing.hdf5',\n",
    "\tBATCH_SIZE,\n",
    "\tpreprocessors=[sp, mp, iap],\n",
    "\tclasses=NUM_CLASSES)\n",
    "\n",
    "predictions = model.predict(\n",
    "\ttestGen.generator(),\n",
    "\tsteps=testGen.numImages // BATCH_SIZE, \n",
    "\tmax_queue_size=10)\n",
    "\n",
    "trueLabels = list(testGen.db[\"labels\"])\n",
    "predictedLabels = list(predictions.argmax(axis=1))\n",
    "\n",
    "# compute the rank-1 and rank-5 accuracies\n",
    "(rank1, _) = rank5_accuracy(predictions, trueLabels)\n",
    "print(\"[INFO] rank-1: {:.2f}%\".format(rank1 * 100))\n",
    "\n",
    "testGen.close()\n",
    "\n",
    "print(\"\\n\\n[INFO] Calculating Confusion Matrix\")\n",
    "cm = confusion_matrix(\n",
    "    y_true = trueLabels[:96],\n",
    "    y_pred = predictedLabels\n",
    ")\n",
    "plot_confusion_matrix(cm, ['No DR',' DR'], False, \"Confusion Matrix\")\n",
    "\n",
    "print(\"[INFO] Generating the Classification Report\")\n",
    "print(classification_report(\n",
    "\ty_true = trueLabels[:96],\n",
    "\ty_pred = predictedLabels,\n",
    "\ttarget_names= ['No DR', 'DR']\n",
    "))\n",
    "\n",
    "print(\"[INFO] Calculating the class likelihood ratios\")\n",
    "\n",
    "ratios = class_likelihood_ratios(\n",
    "\ty_true = trueLabels[:96],\n",
    "\ty_pred = predictedLabels\n",
    ")\n",
    "\n",
    "for c,r in enumerate(ratios):\n",
    "\tprint(\"|\\tClass {}: {:.2f}\".format(c, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a report of the parameters used for training\n",
    "\n",
    "JSON_PATH = os.path.sep.join([OUTPUT_PATH, f'{FILENAME}.json'])\n",
    "\n",
    "with open(JSON_PATH, \"w\") as f:\n",
    "    f.write(json.dumps(report_dict, indent=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66e04bfc85808da2e18bbbef2b64a6be2d087de19c3aa024c126ff1bcb5631ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
