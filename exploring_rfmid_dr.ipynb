{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA RFMiD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import os\n",
    "import progressbar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFMID_PATH = \"./Data/Raw/MultiDiseaseClassification/RfmidMultidisease\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = './DB'\n",
    "if os.path.exists(DB_PATH):\n",
    "    !rm -r {DB_PATH}\n",
    "    os.mkdir(DB_PATH)\n",
    "else:\n",
    "    os.mkdir(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_set(zipFile: str, outputPath: str = DB_PATH):\n",
    "    print(zipFile)\n",
    "    zipFile = os.path.sep.join([RFMID_PATH, zipFile])\n",
    "    !7z x {zipFile} -o{outputPath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation_Set.zip\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs 11th Gen Intel(R) Core(TM) i5-11300H @ 3.10GHz (806C1),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan ./Data/Raw/MultiDiseaseClassification/RfmidMultidiseas                                                                1 file, 1564446026 bytes (1492 MiB)\n",
      "\n",
      "Extracting archive: ./Data/Raw/MultiDiseaseClassification/RfmidMultidisease/Evaluation_Set.zip\n",
      "--\n",
      "Path = ./Data/Raw/MultiDiseaseClassification/RfmidMultidisease/Evaluation_Set.zip\n",
      "Type = zip\n",
      "Physical Size = 1564446026\n",
      "\n",
      "     12% 119 - Evaluation_Set/Validation/203.p                                           25% 238 - Evaluation_Set/Validation/310.p                                           40% 374 - Evaluation_Set/Validation/433.p                                           54% 460 - Evaluation_Set/Validation/510.p                                           70% 500 - Evaluation_Set/Validation/547.p                                           71% 505 - Evaluation_Set/Validation/551.p                                           72% 516 - Evaluation_Set/Validation/561.p                                           77% 551 - Evaluation_Set/Validation/593.p                                           84% 576 - Evaluation_Set/Validation/615.p                                           99% 640 - Evaluation_Set/Validation/97.pn                                          Everything is Ok\n",
      "\n",
      "Folders: 2\n",
      "Files: 641\n",
      "Size:       1564417295\n",
      "Compressed: 1564446026\n",
      "Test_Set.zip\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs 11th Gen Intel(R) Core(TM) i5-11300H @ 3.10GHz (806C1),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan ./Data/Raw/MultiDiseaseClassification/RfmidMultidiseas                                                                1 file, 1742451361 bytes (1662 MiB)\n",
      "\n",
      "Extracting archive: ./Data/Raw/MultiDiseaseClassification/RfmidMultidisease/Test_Set.zip\n",
      "--\n",
      "Path = ./Data/Raw/MultiDiseaseClassification/RfmidMultidisease/Test_Set.zip\n",
      "Type = zip\n",
      "Physical Size = 1742451361\n",
      "\n",
      "     10% 107 - Test_Set/Test/193.p                               23% 239 - Test_Set/Test/311.p                               36% 376 - Test_Set/Test/435.p                               49% 417 - Test_Set/Test/472.p                               63% 456 - Test_Set/Test/507.p                               77% 508 - Test_Set/Test/554.p                               78% 520 - Test_Set/Test/565.p                               82% 551 - Test_Set/Test/593.p                               90% 576 - Test_Set/Test/615.p                               91% 585 - Test_Set/Test/623.p                               92% 591 - Test_Set/Test/629.p                              Everything is Ok\n",
      "\n",
      "Folders: 2\n",
      "Files: 641\n",
      "Size:       1742441359\n",
      "Compressed: 1742451361\n",
      "Training_Set.zip\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs 11th Gen Intel(R) Core(TM) i5-11300H @ 3.10GHz (806C1),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan ./Data/Raw/MultiDiseaseClassification/RfmidMultidiseas                                                                1 file, 4681355361 bytes (4465 MiB)\n",
      "\n",
      "Extracting archive: ./Data/Raw/MultiDiseaseClassification/RfmidMultidisease/Training_Set.zip\n",
      "--\n",
      "Path = ./Data/Raw/MultiDiseaseClassification/RfmidMultidisease/Training_Set.zip\n",
      "Type = zip\n",
      "Physical Size = 4681355361\n",
      "64-bit = +\n",
      "\n",
      "      1% 47 - Training_Set/Training/1038.p                                        2% 61 - Training_Set/Training/1050.p                                        2% 73 - Training_Set/Training/1061.p                                        2% 83 - Training_Set/Training/1070.p                                        3% 95 - Training_Set/Training/1081.p                                        4% 112 - Training_Set/Training/1097.pn                                          4% 125 - Training_Set/Training/1108.pn                                          4% 136 - Training_Set/Training/1118.pn                                          5% 148 - Training_Set/Training/1129.pn                                          5% 158 - Training_Set/Training/1138.pn                                          6% 170 - Training_Set/Training/1149.pn                                          6% 180 - Training_Set/Training/1158.pn                                          7% 197 - Training_Set/Training/1173.pn                                         11% 321 - Training_Set/Training/1285.pn                                         16% 459 - Training_Set/Training/1409.pn                                         18% 515 - Training_Set/Training/146.p                                       19% 530 - Training_Set/Training/1473.pn                                         19% 541 - Training_Set/Training/1483.pn                                         20% 552 - Training_Set/Training/1493.pn                                         20% 555 - Training_Set/Training/1496.pn                                         20% 558 - Training_Set/Training/1499.pn                                         21% 565 - Training_Set/Training/1504.pn                                         23% 583 - Training_Set/Training/1520.pn                                         24% 587 - Training_Set/Training/1524.pn                                         24% 591 - Training_Set/Training/1528.pn                                         25% 594 - Training_Set/Training/1530.pn                                         25% 597 - Training_Set/Training/1533.pn                                         27% 609 - Training_Set/Training/1544.pn                                         27% 612 - Training_Set/Training/1547.pn                                         28% 616 - Training_Set/Training/1550.pn                                         28% 619 - Training_Set/Training/1553.pn                                         28% 620 - Training_Set/Training/1554.pn                                         30% 631 - Training_Set/Training/1564.pn                                         31% 639 - Training_Set/Training/1571.pn                                         32% 647 - Training_Set/Training/1579.pn                                         32% 6       32% 649 - Training_Set/Training/1580.pn                                         32% 6       34% 666 - Training_Set/Training/1596.pn                                         34% 6       34% 667 - Training_Set/Training/1597.pn                                         34% 6       36% 679 - Training_Set/Training/1607.pn                                         36% 6       36% 680 - Training_Set/Training/1608.pn                                         38% 698 - Training_Set/Training/1624.pn                                         40% 714 - Training_Set/Training/1639.pn                                         40% 716 - Training_Set/Training/1640.pn                                         40% 7       42% 730 - Training_Set/Training/1653.pn                                         42% 731 - Training_Set/Training/1654.pn                                         42% 7       42% 732 - Training_Set/Training/1655.pn                                         42% 7       44% 747 - Training_Set/Training/1669.pn                                         45% 749 - Training_Set/Training/1670.pn                                         45% 7       45% 751 - Training_Set/Training/1672.pn                                         45% 7       46% 763 - Training_Set/Training/1683.pn                                         47% 763 - Training_Set/Training/1683.pn                                         47% 764 - Training_Set/Training/1684.pn                                         47% 7       47% 765 - Training_Set/Training/1685.pn                                         47% 7       48% 776 - Training_Set/Training/1695.pn                                         48% 7       48% 777 - Training_Set/Training/1696.pn                                         49% 777 - Training_Set/Training/1696.pn                                         49% 778 - Training_Set/Training/1697.pn                                         49% 784 - Training_Set/Training/1701.pn                                         52% 808 - Training_Set/Training/1723.pn                                         54% 818 - Training_Set/Training/1732.pn                                         57% 874 - Training_Set/Training/1783.pn                                         60% 946 - Training_Set/Training/1848.pn                                         62% 980 - Training_Set/Training/1879.pn                                         62% 982 - Training_Set/Training/1880.pn                                         62% 983 - Training_Set/Training/1881.pn                                         62% 988 - Training_Set/Training/1886.pn                                         63% 1000 - Training_Set/Training/1897.p                                         64% 1006 - Training_Set/Training/1901.p                                         64% 1010 - Training_Set/Training/1905.p                                         65% 1016 - Training_Set/Training/1910.p                                         66% 1021 - Training_Set/Training/1915.p                                         66% 1024 - Training_Set/Training/1918.p                                         67% 1040 - Training_Set/Training/203.pn                                         68% 1054 - Training_Set/Training/216.pn                                         69% 1083 - Training_Set/Training/242.pn                                         69% 1096 - Training_Set/Training/254.pn                                         70% 1108 - Training_Set/Training/265.pn                                         70% 1118 - Training_Set/Training/274.pn                                         70% 1128 - Training_Set/Training/283.pn                                         71% 1138 - Training_Set/Training/292.pn                                         71% 1148 - Training_Set/Training/300.pn                                         71% 1158 - Training_Set/Training/31.p                                       72% 1168 - Training_Set/Training/319.pn                                         72% 1179 - Training_Set/Training/329.pn                                         72% 1184 - Training_Set/Training/333.pn                                         72% 1185 - Training_Set/Training/334.pn                                         73% 1209 - Training_Set/Training/356.pn                                         74% 1229 - Training_Set/Training/374.pn                                         74% 1237 - Training_Set/Training/381.pn                                         75% 1248 - Training_Set/Training/391.pn                                         75% 1258 - Training_Set/Training/40.p                                       75% 1268 - Training_Set/Training/409.pn                                         76% 1279 - Training_Set/Training/419.pn                                         76% 1288 - Training_Set/Training/427.pn                                         77% 1298 - Training_Set/Training/436.pn                                         77% 1308 - Training_Set/Training/445.pn                                         77% 1320 - Training_Set/Training/456.pn                                         77% 1323 - Training_Set/Training/459.pn                                         78% 1344 - Training_Set/Training/478.pn                                         79% 1354 - Training_Set/Training/487.pn                                         79% 1364 - Training_Set/Training/496.pn                                         79% 1367 - Training_Set/Training/499.pn                                         80% 1389 - Training_Set/Training/518.pn                                         80% 1399 - Training_Set/Training/527.pn                                         81% 1409 - Training_Set/Training/536.pn                                         81% 1419 - Training_Set/Training/545.pn                                         81% 1428 - Training_Set/Training/553.pn                                         82% 1438 - Training_Set/Training/562.pn                                         82% 1443 - Training_Set/Training/567.pn                                         83% 1474 - Training_Set/Training/595.pn                                         83% 1483 - Training_Set/Training/602.pn                                         84% 1492 - Training_Set/Training/610.pn                                         84% 1501 - Training_Set/Training/619.pn                                         84% 1506 - Training_Set/Training/623.pn                                         84% 1510 - Training_Set/Training/627.pn                                         84% 1514 - Training_Set/Training/630.pn                                         85% 1517 - Training_Set/Training/633.pn                                         85% 1521 - Training_Set/Training/637.pn                                         85% 1526 - Training_Set/Training/641.pn                                         85% 1530 - Training_Set/Training/645.pn                                         85% 1533 - Training_Set/Training/648.pn                                         85% 1537 - Training_Set/Training/651.pn                                         85% 1540 - Training_Set/Training/654.pn                                         86% 1544 - Training_Set/Training/658.pn                                         88% 1605 - Training_Set/Training/712.pn                                         92% 1709 - Training_Set/Training/806.pn                                         96% 1815 - Training_Set/Training/901.pn                                        Everything is Ok\n",
      "\n",
      "Folders: 2\n",
      "Files: 1921\n",
      "Size:       4681024067\n",
      "Compressed: 4681355361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[unzip_set(z) for z in os.listdir(RFMID_PATH) if '.zip' in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir(DB_PATH):\n",
    "    !mv {os.path.sep.join([DB_PATH, f])}/* {DB_PATH}\n",
    "    !rm -r {os.path.sep.join([DB_PATH, f])}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_set(csv_file: str, folder: str, column: str):\n",
    "\n",
    "    df_columns = [\"ID\"]\n",
    "    df_columns.append(column)\n",
    "\n",
    "    # read csv file from the DB path\n",
    "    csv_path = os.path.sep.join([DB_PATH, csv_file])\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "    # get ID + specified disease column\n",
    "    dr_df = df.loc[:, df.columns.isin(df_columns)]\n",
    "\n",
    "    # dictionary column:[ID]\n",
    "    dir_structure = {f'{i}':list(dr_df.loc[dr_df[column] == i].pop(\"ID\")) for i in range(2)}\n",
    "\n",
    "    # creating a folder named as {column} containing all files in [ID]\n",
    "    for k in dir_structure.keys():\n",
    "        class_path = os.path.sep.join([DB_PATH, folder, k])\n",
    "\n",
    "        if not os.path.exists(class_path):\n",
    "            os.mkdir(class_path)\n",
    "        \n",
    "        widgets = [\n",
    "            f\"Building Dataset {folder}/{k}: \",\n",
    "            progressbar.Percentage(),\n",
    "            \" \",\n",
    "            progressbar.Bar(),\n",
    "            \" \",\n",
    "            progressbar.ETA()\n",
    "        ]\n",
    "\n",
    "        \n",
    "        for i, v in enumerate(dir_structure[k]):\n",
    "\n",
    "\n",
    "            pbar = progressbar.ProgressBar(\n",
    "                maxval=len(dir_structure[k]),\n",
    "                widgets=widgets\n",
    "            ).start()\n",
    "\n",
    "            destination = os.path.sep.join([class_path, f'{v}.png'])\n",
    "            origin = os.path.sep.join([DB_PATH, folder, f'{v}.png'])\n",
    "            !mv {origin} {destination}\n",
    "\n",
    "            pbar.update(i)\n",
    "\n",
    "        pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Dataset Training/0: 100% |#############################| Time: 0:00:00\n",
      "Building Dataset Training/1: 100% |#############################| Time: 0:00:00\n",
      "Building Dataset Validation/0: 100% |###########################| Time: 0:00:00\n",
      "Building Dataset Validation/1: 100% |###########################| Time: 0:00:00\n",
      "Building Dataset Test/0: 100% |#################################| Time: 0:00:00\n",
      "Building Dataset Test/1: 100% |#################################| Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "csv_files = [f for f in os.listdir(DB_PATH) if '.csv' in f]\n",
    "folders = [f for f in os.listdir(DB_PATH) if f not in csv_files]\n",
    "\n",
    "for csv in csv_files:\n",
    "    for f in folders:\n",
    "        if f in csv:\n",
    "            restructure_set(csv, f, 'DR')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tesis_lib.preprocessing.aspectawareprocessor import AspectAwareProcessor\n",
    "from tesis_lib.io.hdf5datasetwriter import HDF5DatasetWriter\n",
    "\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './DB'\n",
    "\n",
    "IM_SIZE = 256\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_HDF5_PATH = os.path.sep.join([DATASET_PATH, 'hdf5'])\n",
    "if os.path.exists(DATASET_HDF5_PATH):\n",
    "    !rm -r {DATASET_HDF5_PATH}\n",
    "\n",
    "os.mkdir(DATASET_HDF5_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aap = AspectAwareProcessor(IM_SIZE,IM_SIZE)\n",
    "# iap = ImageToArrayPreprocessor()\n",
    "(R,G,B) = ([],[],[])\n",
    "\n",
    "path = os.path.sep.join([DATASET_PATH, \"Training\"])\n",
    "class_paths = [os.path.sep.join([path, im_class]) for im_class in os.listdir(path)]\n",
    "\n",
    "imagePaths = []\n",
    "[imagePaths.extend(paths.list_images(cp)) for cp in class_paths]\n",
    "labels = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "(trainPaths, valPaths,trainLabels,valLabels) = train_test_split(\n",
    "  imagePaths,\n",
    "  labels,\n",
    "  train_size=450,\n",
    "  test_size=100,\n",
    "  stratify=labels, \n",
    "  random_state = 42)\n",
    "\n",
    "assert trainLabels.shape[0] == len(trainPaths)\n",
    "assert valLabels.shape[0] == len(valPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data points = 450\n",
      "Training data points = 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data points = {trainLabels.shape[0]}\")\n",
    "print(f\"Training data points = {valLabels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.sep.join([DATASET_PATH, \"Test\"])\n",
    "class_paths = [os.path.sep.join([path, im_class]) for im_class in os.listdir(path)]\n",
    "\n",
    "imagePaths = []\n",
    "[imagePaths.extend(paths.list_images(cp)) for cp in class_paths]\n",
    "labels = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "(_, testPaths,_,testLabels) = train_test_split(\n",
    "  imagePaths,\n",
    "  labels,\n",
    "  train_size=450,\n",
    "  test_size=124,\n",
    "  stratify=labels, \n",
    "  random_state = 42)\n",
    "\n",
    "assert testLabels.shape[0] == len(testPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data points = 124\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data points = {testLabels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOoUuQ4E_2_N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building train Set: 100% |######################################| Time: 0:00:29\n",
      "Building val Set: 100% |########################################| Time: 0:00:08\n",
      "Building test Set: 100% |#######################################| Time: 0:00:11\n"
     ]
    }
   ],
   "source": [
    "DATA_PATHS = [\n",
    "    ('train', trainPaths, trainLabels, f'./DB/hdf5/Training.hdf5'),\n",
    "    ('val', valPaths, valLabels, f'./DB/hdf5/Validation.hdf5'),\n",
    "    ('test', testPaths, testLabels, f'./DB/hdf5/Testing.hdf5'),\n",
    "]\n",
    "\n",
    "for (dType, imagePaths, labels, output) in DATA_PATHS:\n",
    "  if os.path.exists(output):\n",
    "    os.remove(output)\n",
    "  writer = HDF5DatasetWriter((len(imagePaths), IM_SIZE,IM_SIZE,3), output)\n",
    "\n",
    "  widgets = [\n",
    "      f\"Building {dType} Set: \",\n",
    "      progressbar.Percentage(),\n",
    "      \" \",\n",
    "      progressbar.Bar(),\n",
    "      \" \",\n",
    "      progressbar.ETA()\n",
    "  ]\n",
    "\n",
    "  pbar = progressbar.ProgressBar(\n",
    "      maxval=len(imagePaths),\n",
    "      widgets=widgets\n",
    "      ).start()\n",
    "\n",
    "  for (i, (path,label)) in enumerate(zip(imagePaths, labels)):\n",
    "      image = cv2.imread(path)\n",
    "      try:\n",
    "        image = aap.preprocess(image)\n",
    "      except Exception:\n",
    "        display(f\"[WARNING] Skipped {path.split('/')[-1]}\")\n",
    "        continue\n",
    "\n",
    "      if dType == \"train\":\n",
    "        (b,g,r) = cv2.mean(image)[:3]\n",
    "        R.append(r)\n",
    "        G.append(g)\n",
    "        B.append(b)\n",
    "      \n",
    "      writer.add([image], [label])\n",
    "      pbar.update(i)\n",
    "\n",
    "  pbar.finish()\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing means...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] serializing means...\")\n",
    "D = {\n",
    "    \"R\": np.mean(R),\n",
    "    \"G\": np.mean(G),\n",
    "    \"B\": np.mean(B)\n",
    "}\n",
    "with open('./DB/hdf5/diat_ret.json', \"w\") as f:\n",
    "    f.write(json.dumps(D))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAPyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a224baf6a6839bacf51cec99cfcbfd7bfde95820515766c8297319e0ba4e2dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
